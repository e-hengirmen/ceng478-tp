For parallel matrix multiplication of 2 N$^2$ matrices A and B to create a N$^2$ matrix C there are 3 basic methods that comes to mind.
\begin{enumerate}
	\item Every process will calculate rows of the C matrix
	\item Every process will calculate columns of the C matrix
	\item Every process will calculate a block of the C matrix
\end{enumerate}
Even though in the end there will be exactly the same number of calculations the first 2 methods has an inefficient side opposed to the 3rd method. The problem with the first 2 methods comes from the way the matrix multiplication works. If we are using matrix row method then every process will only need that corresponding row from the A matrix but since the elements in a rows are in every column then every process will need all of the B matrix to process their rows. \\
\\
so every process would need to get N/P rows from matrix A and all of the B matrix which means to send the matrices we ould need to make 1 Broadcast operation and 1 scatter operation from process 0. Broadcast would take O($log(p)(t_s+$N$^2t_m$)) time (since it is the whole matrix the message size is N$^2$). On the other hand scatter operation would be done on rows and would take O($log(\sqrt{p})$(2t$_s$+$N^2\frac{1+\sqrt{p}}{\sqrt{p}}t_m$))) so in the end just sending the matrices would take O(N$^2$log(p)) operations(since log(p) is 2log($\sqrt{p}$))\\
\\
\textbf{Note:} Scatter would take O($log(\sqrt{p})$(2t$_s$+$N^2\frac{1+\sqrt{p}}{\sqrt{p}}t_m$))) because we are assuming that in a 2D mesh network the system would first scatters data between one row of processes which would take $log(\sqrt{p})$(t$_s$+$N^2t_m$) then we would need to scatter $\frac{N^2}{\sqrt{p}}$ between the columns which would take $log(\sqrt{p})$(t$_s$+$\frac{N^2}{\sqrt{p}}t_m$)\\
\\
On the other hand for the block approach we will only need to send rows from A matrix and columns from B matrix normally and since we chose cannon's algorihm we will only send \textbf{blocks} of $\frac{N}{\sqrt{p}}\times \frac{N}{\sqrt{p}}$ instead. Which would need 2 scatter operations of complexity O($log(\sqrt{p})$(2t$_s$+$N^2\frac{1+\sqrt{p}}{\sqrt{p}}t_m$))).

and we will send N$^2$/$\sqrt{p}$ entrys each time so the total complexity of sending messages would be \(2\sqrt{p}log(\sqrt{p})(t_s+\frac{N^2}{\sqrt{p}}t_m)\)


For matrix multiplication, we can intuitively see that, to calculate an entry, we would first need to make N separate multiplications for every N$^2$ entry of the newly created matrix and then add them up. Let's say we have P amount of processes that we can use to solve this problem. To calculate an arbitrary c$_{xy}$, every process will have N/P different pairs that need to be multiplied(assuming P is less than M). However, after these have been calculated, we will have M values that the program needs to add up. Instead of adding them one by one and doing M-1 sequential operations, we can separate them into pairs, and this way decrease the time complexity of adding them. Normally calculating 1 entry would take M multiplications and M-1 additions, but with the parallel model, every process will first multiply them concurrently and then add them up in O(logM) time(assuming we have enough processes). So the complexity of calculating an entry will reduce from O(M) to O(log(M)). (we will use Reduce operation so it will actually cost log(P)(t$_s$+mt$_m$))\\
\\
\textbf{Note:} If we wanted to do this addition, we will first need to do n/2 operations without any pre-
requirements and send the results to corresponding processes. For any remaining n/2 operations. We will wait for the required 2 signals from its required calculations to do the remaining ones. For example (1+2+3+4+5+6+7+8):\\
Instead of doing 7 sequential additions (((((((1+2)+3)+4)+5)+6)+7)+8)\\
We will instead make it in 3 operation groups. First, we will calculate 4 operations at the same time with 4 different processes:\\
\\
p1-$>$ 1+2=3\\   
p2-$>$ 3+4=7\\   
p3-$>$ 5+6=11\\   
p4-$>$ 7+8=15\\
\\
and send p3 and p4's solutions to p1 and p2 respectively(cost: (t$_s$+mt$_m$)))
In the second step, we will do the same thing. But since we have 4 numbers, we will do it with 2 processes:\\
\\
p1-$>$ 3+7=10\\   
p2-$>$ 11+15=26\\
\\
and send p2's result to p1(cost: (t$_s$+mt$_m$))).
At the last step, we will add them up and find the result 36. And we had logP(t$_{calculation}$+t$_s$+mt$_m$)\\
\\
Also, do not forget that the new matrix will be a M$\times$K matrix. This means that we need to do these operations for every M*K entry in the new matrix. However, assuming we have enough proceses, we can send every operation to different groups of processes. And this way, we can improve the complexity of matrix multiplication from O(N*M*K) to O(log(M))\\
\\
\textbf{Important Note 1(for enough processes):} The real complexity of the matrix multiplication would not be O(log(M)) even if we have enough number of processes the best complexity would get be O(N*K) even though the operations would be done in O(log(M)) time. The reason for this is we would need to combine the data. Moreover, while sending messages is an O(t$_s$+mt$_m$) operation; for every entry of the matrix the receiver process(after the final computation one of the processes would need to gather every entry) would need to receive them all. Because of that the complexity cannot be improved that much. Even with the MPI\_Gather(which would take log(N*K)t$_s$+(N*K-1)mt$_m$ time) our complexity will be log(P)(t$_{calculation}$+t$_s$+mt$_m$)+log(N*K)t$_s$+(N*K-1)mt$_m$ which would make the complexity(assuming P is as high as N*M*K or higher) O(N*K*m*t$_m$) or O(N*K) since m and t$_m$ are constant.\\
\\
\textbf{Important Note 2(for not enough processes):} We would need to do N*M*K/P multiplications per process first. Then in every process we will have calculated M/P multiplications for every N*K entry which needs to be added in (M-1)/P addition operations so in total we will do ((M-1)/P) additions sequentially N*K times in every process. After that we would need to add these seperate parts from every process log(P)(t$_s$+m*t$_m$) m is N*K since we are gonna do this for every c$_xy$.
so in the end we have
\begin{itemize}
	\item N*M*K/P\quad from multiplications
	\item N*K*(M-1)/P\quad from sequential additions
	\item log(P)(t$_s$+N*K*t$_m$) \quad from parellel additions
\end{itemize}
So the total complexity for this case would be:\\
\[O(log(P)t_s+NK(\dfrac{2M-1}{P}+log(P)t_m))\]
and since t$_s$ and t$_m$ are constants and log(P) is lower then NKlog(p) we can simplify the complexity into:
\[O(NK(\dfrac{M}{P}+log(P)))\]

 